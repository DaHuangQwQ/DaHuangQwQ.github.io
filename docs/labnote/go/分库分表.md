# 分库分表

## 类型

分库分表的类型（或策略）包括：

1. **水平分表**：
   - 将同一张表的数据按行划分，分散到多个表中。例如，可以按用户ID的范围将数据分为多个表（如 `user_1`、`user_2`）。
2. **垂直分表**：
   - 将一张表的不同列拆分到多个表中，以减少每张表的字段数量和提高查询效率。例如，用户表可以分为基本信息表和详细信息表。
3. **水平分库**：
   - 将相同的表结构复制一份到另一个库中，每个库的表结构是一样的，可以减少单一数据库的读写压力，在大量的情况下提高读写性能。例如，`database1`、`database2`。
4. **垂直分库**：
   - 将数据分散到不同的数据库实例中。可以根据业务功能或模块进行分库，如将用户数据、订单数据分别存储在不同的数据库中。

## 分区表

MySQL分区 是一种数据库优化的技术，它允许将一个大的表、索引或其子集分割成多个较小的、更易于管理的片段，这些片段称为“分区”。每个分区都可以独立于其他分区进行存储、备份、索引和其他操作。这种技术主要是为了改善大型数据库表的查询性能、维护的方便性以及数据管理效率

分区技术是将表中的记录分散到不同的物理文件中，即每个分区对应一个.idb文件。这是MySQL 5.1及以后版本支持的一项高级功能，旨在提高大数据表的管理效率和查询性能

在MySQL中，分区是局部的，意味着数据和索引都存储在各自的分区内。目前，MySQL尚不支持全局分区索引

分区表，不同的分区建议在不同的磁盘存储上，提升 IO

### 使用场景

1. **性能提升**
2. **管理简化**
3. **数据归档和清理**
4. **可扩展性**

## 分库分表

为什么要分库分表：遇到了读写瓶颈

大多数时候读瓶颈是可以通过的分区、加从库来解决的。只有在数据量非常大的时候，这种情况下分区表或者加从库可能效果不太好。比如说数据量大了之后，B+ 树的高度变高了，索引过于庞大以至于没法装进去内存中等。读瓶颈可以通过分表、分库或者同时分库分表来解决。

而写瓶颈和读瓶颈稍微不同。分区表能够缓解写瓶颈，但是不能彻底解决，而且增加从库毫无效果——因为从库是只用来服务读请求的。因此，写瓶颈只有两条路：一条路是增加硬件资源，也就是更大的内存，更快的磁盘，更快的 CPU；另外一条路就是分库分表。

而分库或者分表在解决写瓶颈上的效果也是有差异的。分表之后，单表数据量下降，那么写瓶颈会得到缓解，但是也不能彻底解决，因为此时没有分库，所有的写请求还是落到这个数据库实例上，瓶颈依旧在。分库之后，如果这些库还在同一个数据库实例上，那么效果和分表差不多。因此解决写瓶颈最彻底的方案就是**分实例**。也就是部署多个数据库，这样写请求平均分到了多个数据库上，自然就没有写瓶颈的问题了。在最特殊的情况，如果写瓶颈是因为硬件资源带来的，那么这些数据库都要分布在不同的机器上，才能解决问题。

因此总结下来：

- 读瓶颈，可以考虑分区或者加从库，分库分表也能解决问题；
- 写瓶颈，加从库毫无效果，分区与分库分表都能缓解，彻底解决要分实例，并且最好不同的数据库实例在不同的机器上；

很常见的说法是一个表的数据量超过 500w/2000w 就要分库分表，它描述的是现象，本质上就是在这个量级有可能出现了度写瓶颈。记住核心要不要判定分库分表，就始终是四个字：**读写瓶颈**。

> 读瓶颈，可加从库，可分区，分库分表更加好；写瓶颈，勿加从库，分区分库分表可缓解，彻底解决要分实例

### 为什么不适用分区表

简单来说：分区表和分库分表都能解决读写瓶颈，但是分库分表在大数据场景、写瓶颈下效果会更好。

你可以设想，一张表在分区之后，每个分区的数据量都减少了，因此读写效率都能提高，也就是解决了读写瓶颈，或者说至少极大的缓解了读写瓶颈问题。

但是如果要是数据量非常庞大，以至于单一分区内部都有很多数据，就只能考虑分库分表。而在其中，单纯分表的话，应对写瓶颈的效果是很差的。比如说一张表分了 10 张表，但是都在同一个数据库实例上，那么这个实例的写压力在分表前后并没有多少变化。这种时候就应该分库，并且在分库之后，应该将不同的库放到不同的数据库实例上。

如果是在聊到了某个业务场景，甚至于直接就是你面试项目里面的某个点的时候，面试官问出了这个问题，那么你就需要扣紧当前的语境、场景来回答。

## 怎么解决主键问题

常见的主键解决方案有：

- 使用 uuid
  - 优点：简单
  - 缺点：uuid 不是自增的，所以性能比自增主键要差一些；存储成本高，uuid 比一般的自增主键要长；
- 控制自增步长。举个例子，你分库分表之后总共有 3 张表 A B C，而后你控制步长是 3，而后 A 从 1 开始，生成 1 4 7 10... B 从 2 开始，生成 2 5 8 11... C 从 3 开始，生成 3 6 9 12...
  - 优点：简单，单一表内的主键是自增的；
  - 缺点：如果主键也是分库分表的键，那么扩容会出现问题；性能取决于数据库；
  - 变种：如果担忧数据库有性能问题，那么可以用 Redis；
- 雪花算法：
  - 优点：高性能，易扩展
  - 缺点：
    - 时钟回拨问题：也就是遇到了所谓的润秒，这个时候生成的 ID 就有可能重复
    - 非严格自增：即从全局来看，有可能机器序列比较小的反而靠后生成了 id
  - 变种：雪花算法有非常多种变种，核心就是控制雪花算法的不同部分的比特数量

这三种算法也可以看做是全局唯一 ID 生成的解决方案。

而更加高级的回答，则基本上和《什么是雪花算法》这个部分一致。包括：

- 调整雪花算法的不同分段的比特数量
- 解决序列号耗尽的问题
- 数据偏移（积压） 的问题

更加高级的亮点，则是落在怎么优化性能上。

1. uuid 的优缺点都很明显，优点是极其**简单**，不依赖于任何东西。缺点则是 uuid 不是**自增**的，并且长度比较长，需要比较多的存储空间。
2. 控制步长的自增主键也很**简单好用**，核心就是每张表从不同的起点开始，按照固定步长来生成主键，这种情况下也不会有冲突，并且在一张表内必然是自增的。缺点则是在扩容的时候会有问题。
3. 雪花算法性能好，易扩展。核心缺点则是严重依赖于时间戳，不管是服务器时间戳不准确，还是时钟回拨问题，都可能生成重复的 ID。雪花算法的精髓在于，可以根据自己的业务需要灵活设定每一个段。一个典型的例子就是某外卖平台用用户 ID 的后四位来分库分表，于是在订单的主键生成算法里面就用用户的后四位取代了机器序列号，而后在序列号部分则是随机生成。

> uuid 不自增，控制步长难扩容，雪花算法靠时间

此外，还有两个问题需要考虑。一个是雪花算法序列号耗尽的问题，这个可以通过增加序列号的比特位来解决，并且正常来说没有什么业务有那么大的并发量。比如说可以通过将时间戳压缩 1 比特，将序列号扩展为 13 比特，那么一毫秒内能产生的 ID 数量就翻了一倍。

另外一个问题就是 ID 偏移问题。在并发度不高的情况下，很容易出现生成的 ID 的序列号部分都是 1 或者 2这种很小的数字。例如说生成的 ID 全部是 10w001, 10w0002, 11w001, 12w001 这种。解决方案就是可以尝试让序列号从一个随机数开始，例如说在当前毫秒里面从 100 开始，下一毫秒从 200 开始。

> 序列耗尽加比特，ID 偏移就随机；

在高并发的时候，也要考虑进一步优化生成 ID 的性能。有一些比较常见的优化方案：例如将雪花算法集群独立部署

- 批量获取。也就是说，线程（协程）每次获取 ID 不是获取 1 个 ID，而是获取一批 ID，比如说 100 个 ID，而后自己慢慢用这 100 个ID，用完了再去拿下一批；
- 提前取。也就是说，如果预测接下来会需要新的 ID，又或者前面一批取过来的 ID 快要用完了，就可以提前去拿 ID；
- singleflight 获取。如果发号器是集中部署的，比如有一台机器专门分发 ID，大家都去那里拿，那么可以在每一个业务实例上使用 singleflight 模式，这样即便一个业务实例有 100 个线程去获取 ID，但是只会派出一个线程去真的获取 ID，这一个线程拿到之后转交给别的线程；

> 批量取，提前取，一人取

### 雪花算法

雪花算法常用在分库分表里面生成主键。

具体来说，雪花算法是通过将一个 64 比特的数字进行分段，每一段有不同的含义：

- 1 比特保留
- 41 比特用作时间戳，保存的是毫秒数
- 10 位机器序列号（机器ID）：这一部分也可以进一步划分，比如说 5 比特用来表达数据中心编号，5 比特用来表达数据中心内部机器的 ID
- 12比特序列号：在前面三个部分确定情况下，自增；

雪花算法的性能非常好，并且非常好扩展，只需要增加机器就能扩展。缺点则是雪花算法生成 ID 在全局并不是严格自增的，典型的场景就是机器序列号小的反而比机器序列号大的后生成 ID。不过这一点问题不大，因为它生成的 ID 可以看做是近似自增的，因此效果并不会比严格自增的主键差很多。

此外，雪花算法还对时间戳有极强的依赖。这造成两个严重后果：

- 如果部署了雪花算法的机器实例的时间戳并不同步，那么产生的 ID 会严重失序；
- 如果出现了时钟回拨的情况，例如说典型的处理润秒的情况，就有可能出现重复的 ID；

## 读写分离

读写分离是为了减轻主库压力，提高性能，易于横向扩展。

写走主库，读走从库。反范式则是强制读主库和强制写从路，前者有时候还会用上，后者则几乎不会用到。或者说强制读主库和强制写从库本身就不是一个什么好的实践

正常来说，在没有使用读写分离的时候，所有的读写请求都是落在主库上的，那么主库的压力就会非常大，进一步影响响应时间

而后在引入了读写分离之后，主库服务于写请求，从库服务于读请求，那么主库的压力就会大减，响应时间加快。而对于从库来说，只处理读请求，它的性能一般都非常好，能撑住非常高的并发。而如果要是从库也撑不住了，也可以考虑加从库

在引入读写分离之后，就会遇到新的问题，主从延迟问题。如果一个数据被更新了，还没同步到从库上，那么你此时查询从库读取到的就是老的数据。在这种情况下，就是需要强制指定读请求走主库了

从我的个人经验来说，我会认为这种需要强制走主库的场景，大部分时候是因为代码没写好。比如说之前遇到过的，更新了数据之后，立刻去查询。而这种代码可以通过在方法之间直接传递更新后的数据来规避后续立刻查询的动作。

进一步来说，也存在强制走从库的。比如说强制写入一些数据到从库里面，这种一般是发生在修复数据的场景。这种做法就更差了。

> 主从延迟；主从同步

我之前在做数据库迁移，校验数据的时候，就搞了点小花招。理论上来说，数据校验这个东西只能是通过主库来校验的，毕竟主库和从库之间的数据是存在延迟的。

但是，在数据迁移的场景下，校验本身也是一个并发很高的操作。所以我就采用了一种折中策略，即在校验的时候优先使用从库的数据来校验。但是如果发现从库的数据不一致，那么就会使用主库的数据进行一个二次校验。这样一来，避免了全部数据校验都通过主库导致主库压力巨大的问题。

> 数据迁移和数据校验, 主库二次校验机制

### 怎么在读写分离中，强制 SELECT 使用主库

正常来说，很少有场景会要求 SELECT 走主库。毕竟我们读写分离的目的就是为了让 SELECT 语句走从库，从而降低主库的性能压力。

只有在担忧主从延迟的场景下，才会强制要求在主库上执行 SELECT 语句。

一般来说，支持读写分离的中间件都会提供接口来指定某个查询走主库。

比如说在 JAVA 里面，可能就是按照要求在 Thread Local 里面写入是否使用主库的信息，或者在写数据库查询的时候通过注解来指定使用主库；在 Go 里面就是通过 context.Context 来传递。

还有一种就是通过在 SQL 的注释里面指定使用主库或者从库。一些分库分表中间件，或者数据库网关就是依赖于解析注释中这些信息来判定要不要强制走主库。

但是不管怎么说，SELECT 走主库这种用法还是要尽量避免的。

因为最开始读写分离就是为了降低主库的性能压力。而如果还是要让主库来执行 SELECT 语句，就是放弃了这最大的优势。

从实践上来说，通过良好设计，或者在应用层面上缓存数据是能够避免 SELECT 走主库的。

举个例子来说，比如说有些人依赖于数据库来生成更新时间戳，那么为了获得这个时间戳，就必须在 INSERT 或者 UPDATE 之后立刻 SELECT 来获得时间戳，这就不得不走主库。

那么比较好的做法就是不依赖数据库来生成这种时间戳，而是自己管理，自己生成时间戳，再更新到数据库里面。

> 优化案例：不停机数据迁移

## 分库分表中的分页查询

### 全局方案

全局方案也是大部分分库分表中间件使用的方案。例如说，当搜索的是 SELECT * FROM users LIMIT X, Y。

那么全局方案会把查询发送到 WHERE 条件计算出来的候选表上（这个例子里面没有 WHERE，所以是广播），但是查询中的 LIMIT X, Y 会被重写为 LIMIT 0, X + Y。而后当全部候选表都返回结果之后，将这些结果进行排序，筛选出 LIMIT X, Y 来。

这里有一个可以优化的点，即**如果各个表返回的结果已经是有序了，那么计算全局 LIMIT X, Y 的时候，可以使用归并排序**，一边读数据一边排序。如果要是在读数据排序的过程中，就读到了全局的 LIMIT X, Y，那么剩下的所有的结果都可以丢弃了。

打个比方，就好比我们现在要计算全年级的 20-30 名（LIMIT 20, 10），那么你就需要让每一个班级的班主任，将自己班里的 0-30 名的成绩都提交上来。而后你汇总之后，再从这些人里面筛选出全年级的 20-30 名。之所以必须要各个班主任提交 0-30 名的成绩，是因为有可能全年级的 20-30 都在某个班里，也有可能各个班都有一些。

这个算法的缺点就是，X 和 Y 任何一个数非常大的时候，都会取过来非常多的数据，对分库分表中间件造成巨大的内存和 CPU 压力。

### 二次查询

这个解决思路非常复杂。

- 第一步，将 OFFSET 平均分。也就是说，如果你命中了 N 张表，那么就是改写 SQL 为 LIMIT X/N, Y，而后执行查询。
- 第二步，取第一步的所有的查询的最小值（min），与**各个表**的结果集中的最大值（max），构造一个 BETWEEN min, max 的查询，再次发到各个表上；
- 第三步，将第二步查询到的结果排序
- 第四步，计算最小值（min）在全局里面的偏移量。这个很好计算，也就是第二步查询的结果数量减去第一步查询出来的数量机上 OFFSET/N 的值，就是全局偏移量。

我个人认为，这个算法并没有彻底解决全局方案中的性能问题，但是极大缓解了。不过它和第一种方案比起来，也并不是全方面的占优。在 X 还小的时候，第一种方案少了一次查询，反而更快。但是在 X 很大的时候，那么第二种方案就占优了。

不过在面试的时候，你还是需要回答这个方案的。很多面试官在这些地方缺乏思考，所以可能会认为这是一个非常好的解决方案，实际上并不是的。

### 引入中间表

也就是在全局维护一个中间表，里面有数据的主键，以及排序列。而后你每次分页查询的时候，就先从这里查询。举个例子，假设说你现在的要找最长寿的人，那么就需要维护一个包含两个列的中间表（id, age），每次查询的时候先来这个中间表查询一下，拿到最长寿的人的 ID，再去用户表里面加载完整的数据。

当然，如果你的主键不是分库分表键，那么你就需要在这个中间表里面加上分库分表键。

### 禁用跨页查询

在全局方案里面，你应该注意到，会有性能问题的根源就在于 LIMIT X, Y 需要改写为 LIMIT 0, X+Y，那么不论 X 很大还是 Y 很大，都是要返回巨量数据。而 Y 本身是和业务相关的，因此这个方案的思路就是尝试降低 X。

于是我们想到，如果要是每次查询 X 都是 0，那么性能就很好了。而要控制 X 是 0，就需要控制住翻页，比如说不允许跨页。那么在连续翻页的情况下，我们可以带上前一页的最大值或者最小值，从而控制住 X。

举个例子来说，你现在要按照年龄对用户进行排序。假设现在你查询到了最长寿的 10 个人，其中最年轻的那个人是 120 岁，这种时候如果你要查询接下来第二长寿的 10 个人，那么就只需要查询 SELECT * FROM users WHERE age < 120 LIMIT 0, Y。

如果你允许跨页的时候，你就难以构造出来的 WHERE 里面的 age < 120 这个条件。

### 总结

- 全局方案：XY变 X + Y，内存CPU居高不下，归并排序来优化
- 二次查询：X 变 X除N，BETWEEN随其后，额外数据定偏移
- 引入中间表
- 禁用跨页查询

从面试的角度来说，对于初中级工程师来说，你能够随便回答出来一种就可以了。但是如果你追求的是高薪岗位，那么最好还是全部记一下。尤其是全局方案和二次查询，你至少要记一个。

并且，你在这个问题下可以用禁用跨页查询优化性能的案例来刷亮点。虽然全局方案里面提到归并排序也可以优化性能，但是一般分库分表中间件已经做好了。

> 归并排序优化性能
>
> XY变 X + Y，内存CPU居高不下，归并排序来优化；X 变 X除N，BETWEEN随其后，额外数据定偏移
>
> 亮点：禁用跨页查询优化性能

简单来说，常见的思路有四种：

- 全局方案：也就是将 LIMIT X,Y 改写为 LIMIT 0, X +Y 后，发给 WHERE 命中的表，再将所有的结果进行排序，取全局的 LIMIT X，Y。这个过程可以考虑用归并排序优化。这种解决方案性能比较差，因为不管是 X 大，还是 Y 大，都会产生很多数据，消耗大量 CPU、内存和网络带宽。
- 二次查询：也就是将 LIMIT X, Y 改写为 LIMIT X/N, Y，N 是 WHERE 条件命中的表。而后拿到所有返回结果的最小值，和各个表返回的最大值，构建一个 BETWEEN min, max 的查询，而后根据第二次查询比第一次查询多了多少数据，加上 X/N 的值，就是 min 的全局偏移量，再从 min 出发，拿到全局的 LIMIT X, Y。这种做法同样性能比较差，尤其是查询了两次，会放大数据库的查询流量。
- 引入中间表：将排序列、主键放一张表，在这张表里面查询出来全局的 LIMIT X,Y 的数据，再去对应的表里面加载详细数据。这种做法的缺陷就是需要一个额外的表，占用存储。并且在数据量极大的时候，中间表也装不下那么多数据。
- 禁用跨页查询：这种措施比较简单，也就是禁止跨页，每次翻页的时候，带上上一页的最大值或者最小值作为 WHERE 条件，这样可以确保 LIMIT X, Y 的时候，X 始终是 0。

总体来说，分页查询在分库分表里面是比较难解决的。如果不想自己解决的话，也可以考虑换一个存储中间件，比如说换 ES 之类的。

> 归并排序性能优化

## 分库分表聚合函数

首先是不带 GROUP BY 的情况。

第一个是计数 COUNT。注意 COUNT 里面的字段，以及 WHERE 部分都不影响整体算法；

```
// 原语句
SELECT COUNT(id) FROM users WHERE XXX;// 注意 WHERE 部分不影响

// 改写后的语句
SELECT COUNT(id) FROM users_0 WHERE XXX; // 假设结果是 cnt0
SELECT COUNT(id) FROM users_1 WHERE XXX; // 假设结果是 cnt1

// 那么最终结果就是 COUNT(id) = cnt0 + cnt1
```

而后是求和：

```
SELECT SUM(age) FROM users WHERE XXX;

// 改写后
SELECT SUM(age) FROM users_0 WHERE XXX; // 记为 sum0
SELECT SUM(age) FROM users_1 WHERE XXX; // 记为 sum1

// 最终结果 SUM(age) = sum0 + sum1
```

求最大值：

```
SELECT MAX(age) FROM users WHERE XXX;

// 改写后
SELECT MAX(age) FROM users_0 WHERE XXX; // 记为 max0
SELECT MAX(age) FROM users_1 WHERE XXX; // 记为 max1

// 那么最终结果就是 MAX(age) = max(max0, max1)，也就是说从 max0 和 max1 里面再挑一个最大值
```

求最小值：

```
SELECT MIN(age) FROM users WHERE XXX;

// 改写后
SELECT MIN(age) FROM users_0 WHERE XXX; // 记为 min0
SELECT MIN(age) FROM users_1 WHERE XXX; // 记为 min1

// 那么最终结果就是 Min(age) = min(min0, min1) 也就是从 min0 和 min1 里面再挑一个最小值
```

而求平均值比较特殊，因为改写的时候要改写成为先求 SUM 和 COUNT，再求平均值。

```
SELECT AVG(age) FROM users_0 WHERE XXX; 

// 改写后
SELECT SUM(age), COUNT(age) FROM users_0 WHERE XXX; // 记为 sum0, cnt0
SELECT SUM(age), COUNT(age) FROM users_1 WHERE XXX; // 记为 sum1, cnt1

// 最终结果是 (sum0 + sum1)/(cnt0 + cnt1)
```

在有 GROUP BY 的情况下，计算方式也是类似的，只不过在改写 SQL 的时候要把 GROUP BY 的列放进去 SELECT 里面。例如说：

```
SELECT COUNT(id) FROM users WHERE XXX GROUP BY age;

// 改写后
SELECT COUNT(id), age FROM users_0 WHERE XXX GROUP BY age; // 假设结果是 (10, 18), (12, 35)
SELECT COUNT(id), age FROM users_1 WHERE XXX GROUP BY age; // 假设结果是 (15, 18), (17, 20)

// 那么最终结果就是 (10 + 15 = 25, 18), (17, 20), (12, 35)
```

注意在上面 dbproxy 收到汇总结果之后，再次手动分组（这就是为什么要把 age 加进去 SELECT 里面，因为我们要利用它来分组），而后求和得出最终的计数。

其它聚合函数也是类似的。

但是在一种情况下，是不需要做什么的，这种情况就是 GROUP BY 的列恰好是分库分表键。例如说假设 users 按照肤色来分库分表，那么聚合函数处理起来反而比较简单，以 MAX 为例：

```
SELECT MAX(age), color FROM users GROUP BY color;

// 改写后
SELECT MAX(age), color FROM users_0 GROUP BY color; // 假设说这里只有白种人和黑人两条：(100, 'white),(110,'black')
SELECT MAX(age), color FROM users_1 GROUP BY color; // 假设说这里只有黄种人：(35, 'yellow')

// 那么最终结果就是直接组合在一起的三条：(100, 'white),(110,'black'),(35, 'yellow')
```

所以总结起来就是：COUNT、SUM 二次求和，MIN 、MAX 二次比较，AVG 转 SUM 和 COUNT，GOURP BY 带分库分表键，啥也不用干。

> COUNT、SUM 二次求和，MIN 、MAX 二次比较，AVG 转 SUM 和 COUNT；GROUP BY 普通列，SELECT 加列再分组；GROUP BY 分库分表键，啥也不用干



聚合函数在分库分表里面是一个难点，总体来说可以分成求平均值和求非平均值。

对于 COUNT 和 SUM 来说，就是执行分库分表之后，将结果汇总之后再次求和；

对于 MIN 和 MAX 来说，就是结果汇总之后再次求最小值或者最大值；

对于平均值来说，要改写为求 SUM 和 COUNT，汇总之后再计算平均值；

当然，这里还要进一步结合 GROUP BY 来考虑。

如果 GROUP BY 的列就是普通的列，那么聚合函数的算法还是类似前面的算法，但是有两个不同点：

- SELECT 列里面要加上 GROUP BY 的列；
- dbproxy 汇总结果之后，要按照 GROUP BY 的列再次分组，分组之后再次计算

> 二次分组，再次计算

但是有一种最为特殊的情况，就是如果要是 GROUP BY 后面恰好是分库分表键，那么就汇总结果之后直接返回就可以，不需要再次计算了。

这种情况下性能极好。所以我们在很多时候都是不推荐跨库跨表查询，比如说在这里 GROUP BY 刚好是分库分表键，这意味我们不需要跨库跨表汇总结果之后再次计算，节省了大量的资源。

而作为对比，GROUP BY 后面不是分库分表键的时候，还要自己二次分组，再次计算结果，性能损耗很大。

## 分库分表求平均值

平均值在聚合函数里面是属于比较特殊的。在没有 GROUP BY 的情况下，直接将 AVG 改写为 SUM 和 COUNT，汇总之后再次计算平均值。

例如说 SELECT AVG(age) FROM users，那么就要变成 SELECT SUM(age), COUNT(age) FROM users，而后汇总全部目标表的结果之后，再利用 SUM 和 COUNT 来计算平均值。

在结合 GROUP BY 之后，如果 GROUP BY 后面是普通的列，那么就需要在 SELECT 里面加上 GROUP BY 的列，汇总之后再次分组计算平均值。

例如说 SELECT AVG(age) FROM users GROUP BY color（肤色），变成 SELECT SUM(age), COUNT(age), color FROM users_0..n GROUP BY color，汇总结果之后就需要手动进行一个二次分组，再计算平均值。

如果 GROUP BY 本身恰好是使用分库分表键，那么就不需要这么改写 SQL，只需要汇总一下数据就可以了。

例如说 SELECT AVG(age) FROM users GROUP BY color(肤色， 此时也是分库分表键)，那么直接分库分表之后执行 SELECT AVG(age) FROM users_0..n GROUP BY color 就可以了。

因此也再次印证了分库分表之后不推荐跨库跨表查询这个道理。在 GROUP BY 分库分表键的时候，可以确保同一个组的数据都在同一个表里面，那么 dbproxy 处理起来就很高效。