# 服务治理

- 熔断、限流和降级
- 超时控制
- 隔离（比如核心业务的集群和边缘业务集群的隔离）
- 分组和路由
- 优雅退出

> 连接池隔离在 java 里用的多，在 go 里用的很少主要是 goroutine 太轻量了

## 故障机制

整体来说，你可以认为，服务治理讨论的就是：

- 怎么保证系统不会出现故障？或者说，尽量让系统少出现故障。
- 万一系统出现故障了：
  - 怎么尽快发现出现故障了？
  - 怎么处理出现的故障？
  - 怎么从故障中恢复过来？或者说，怎么退出故障处理机制，恢复正常的业务处理流程？

这也就是整个故障处理的理论：

- 故障检测
- 故障处理
- 故障恢复

### 故障检测

- 静态检测（设置阈值）
- 动态检测（硬件信息，服务本身信息）

### 故障处理

- 同步转异步

> 用 消息队列 可能遇到 消息积压 和 有序消息 的问题

- 执行特殊代码

> 可能返回 err 或者 默认值
>
> 或者 执行一个快路径

- 请求转发

### 故障恢复

该如何确定我的服务是否已经恢复正常了？

- 固定时间等待：例如说等一分钟，就认为已经恢复了
- 实时计算：也就是根据故障检测的算法，实时计算服务端节点的状态
- 试探法：尝试处理请求，而后根据处理结果，来确定系统是否已经恢复

避免抖动：也就是退出故障处理流程的时候，不要立刻引起系统再次触发故障。基本思路就是：

- 结合试探法来逐步放开流量，也可以叫做灰度

#### 几乎通用的策略

大部分时候，故障恢复都可以采用试探 + 逐步放开流量的方式来进行。这里以系统发生故障之后所有请求都返回默认值为例。

- 首先，触发故障修复（返回了默认值）之后，间隔一段时间就试探性地处理一个请求
- 如果该请求被正常处理了，那么就加大流量；如果没有被正常处理，那么就继续返回默认值
- 在逐步加大流量的过程中，如果要是请求又没有被正常处理，那么就减少流量，或者再次进入到返回默认值的状态
- 在不断加大流量之后，直到 100% 的流量都被正常处理了

这种政策， 你可以参考之前我们随机数 + 阈值的流量控制方案。你只需要在这里根据处理结果实时调整阈值就可以

## 微服务流量放大与雪崩

也就是在微服务架构里面，有一个很重要的特性，就是一个单一请求在微服务处理过程中，会产生非常多的服务调用

可以看到，一旦请求本身流量增长了一倍，那么整个系统的实际负载增长，不止一倍

所以我们在做服务治理的时候，也要考虑这个问题。例如说通过限流、熔断等措施防止服务雪崩，或者说风险扩大

## 熔断

熔断是经常使用的一种服务治理手段。它是一种保护机制，用于防止微服务架构中的级联故障

所谓级联故障，就是因为一个节点出错之后，导致别的节点跟着出错。本质上是因为微服务架构流量放大引起的

### 要点

熔断的要点在于：

- 如何判定服务是否需要熔断了？这也就是我们之前说的故障检测，也就是可以考虑静态检测和动态检测
- 熔断之后怎么办？大多数时候都是返回特定错误
- 怎么从熔断之中恢复过来？也一样是试探请求 + 逐步放开流量。

熔断还有一种说法，是说熔断处于三种状态：

- 开放状态：也就是所有的请求都返回特定错误
- 闭合状态：也就是所有的请求都被正常处理
- 半开放状态：一部分请求被正常处理，一部分请求直接返回错误

## 降级

降级本质上和熔断差不多。如果说熔断是直接拒绝全部请求，那么降级就是尽可能返回一个响应。这个响应可以直接是一个提前配置好的默认响应，也可以是走某些特定的快路径

正常都是先执行快路径，再执行慢路径。在降级之后，可以只执行快路径，而不执行慢路径

### 缓存降级方案

一个非常好的面试方案就是将降级用于查询过程

在正常时候，我们都是先查询 Redis。如果 Redis 查询不到，则查询数据库，再回写缓存

但是在降级的时候，我们只查询 Redis。Redis 查询到了，则直接返回数据；如果 Redis 查询不到，则直接返回错误，或者兜底的默认值

这种策略的优势在于

- 应用本身的负载会快速降低。因为只查询 Redis，所以会很快，因此请求被快速处理完毕，就能腾出资源来
- 能撑住极高并发。整个瓶颈变成了 Redis。注意，即便缓存命中率极高，但是少数的数据库查询也会极大拖累并发
- 能保住数据库。例如说 Redis 本身有问题，或者网络有问题，在这种策略之下，数据库不会被请求压垮

### 跨服务降级

例如说在用户服务上，有增删改和查询服务。那么在资源不足的时候，就可以考虑将增删改停掉，全力支持查询服务

类似地可以做得更加高级：

- 在集群层面上，如果服务器资源不足，那么就将边缘业务停掉，腾出服务器资源来给核心服务
- 如果是读服务和写服务分组部署的模式，那么也可以将写服务停掉，调用资源支持读服务
- 同一个节点上部署的不同服务，可以按照重要性从不重要到重要，逐步停掉服务，直到腾出来足够的资源

## 限流

限流是指，当判定系统已经无法处理更多的请求的时候，就会执行限流策略

### 被限流的请求怎么办？

很少有人会仔细讨论限流中被限流的请求该怎么办？

实际上也可以考虑：

- 同步转异步：也就是被限流的请求临时保存下来，后续再处理
- 执行特殊代码：例如直接返回默认值
- 转发请求：例如说通知客户端换一个节点重试

从这里你就能看出来，限流、熔断和降级之间的界限不是非常分明

### 针对什么限流？

在实践中，你可以考虑：

- 针对单机限流，或者针对集群限流
-  针对整个应用限流，也可以针对应用提供的某个服务限流。例如说可以整个用户服务限流，也可以是用户服务内部的某个接口（例如说更新信息）限流
- 针对业务对象限流：这个就可以完全根据你的业务特征来设置，非常灵活
  - 针对用户限流：例如说 VIP 用户不限流，但是普通用户限流
  - 针对 IP 限流：我们之前在 Web 登录阶段采用过

### 限流算法

- 计数器

  > 收到请求的时候，计数器 +1；返回响应的时候，计数器-1

- 固定窗口

  > 将时间切成一个个窗口，确保每个窗口内的请求数量没有超过阈值

- 滑动窗口

  > 你可以认为自始至终只有一个窗口，这个窗口就是从当前时间往前回溯窗口大小的一段时间，在这个窗口内，只能处理固定数量的请求

- 令牌桶

  > 令牌桶算法要点：
  >
  > - 有一个人按一定的速率发令牌
  > -  令牌会被放到一个桶里
  > - 每一个请求从桶里面拿一个令牌
  > - 拿到令牌的请求就会被处理
  > - 没有拿到令牌的请求就会：
  >   - 直接被拒绝
  >   - 阻塞直到拿到令牌或者超时
  >
  > 允许积压。也就是说可以攒一些令牌，那么突发流量来的时候，有更多的请求可以拿到令牌

- 漏桶

  > 限流算法：漏桶漏桶算法要点：
  >
  > - 有一个人按一定的速率发令牌
  > - 每一个请求拿一个令牌
  > - 拿到令牌的请求就会被处理
  > - 没有拿到令牌的请求就会：
  >   -  直接被拒绝
  >   - 阻塞直到拿到令牌或者超时
  >
  > 没有积压，绝对均匀。漏桶可以做到，不管什么时候，放过去请求的速率都是均匀的



## 总结：熔断、限流、降级用哪个？

- 如果你希望即便出现了各种故障，但是服务也要尽可能保持可用，那么应该使用降级
- 如果你希望服务尽快从故障中恢复过来，那么应该选用熔断
- 如果你希望至少有一部分请求能够被正确处理，那么应该选用限流

## 总结：动态判定

正如之前我们多次学到的，你完全可以根据实际业务、服务信息来判定服务的状态

可以是硬件指标：例如 CPU、内存、磁盘 IO

可以是服务指标：例如响应时间，超时比率等

而后，一旦判定服务已经出现故障了，就可以从熔断、限流、降级里面挑一个来执行

最后恢复过程，同样可以综合硬件指标和服务指标，来判定是加大流量还是降低流量

PS：实践中，很少采用这种复杂的策略，也就是出去宣讲、汇报、晋升答辩、面试的时候会吹嘘这种策略



限流阈值如何确定？ 压测
