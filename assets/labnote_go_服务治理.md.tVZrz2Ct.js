import{_ as l,c as i,o as a,V as e}from"./chunks/framework.jgiY9GFO.js";const q=JSON.parse('{"title":"服务治理","description":"","frontmatter":{},"headers":[],"relativePath":"labnote/go/服务治理.md","filePath":"labnote/go/服务治理.md"}'),o={name:"labnote/go/服务治理.md"},t=e('<h1 id="服务治理" tabindex="-1">服务治理 <a class="header-anchor" href="#服务治理" aria-label="Permalink to &quot;服务治理&quot;">​</a></h1><ul><li>熔断、限流和降级</li><li>超时控制</li><li>隔离（比如核心业务的集群和边缘业务集群的隔离）</li><li>分组和路由</li><li>优雅退出</li></ul><blockquote><p>连接池隔离在 java 里用的多，在 go 里用的很少主要是 goroutine 太轻量了</p></blockquote><h2 id="故障机制" tabindex="-1">故障机制 <a class="header-anchor" href="#故障机制" aria-label="Permalink to &quot;故障机制&quot;">​</a></h2><p>整体来说，你可以认为，服务治理讨论的就是：</p><ul><li>怎么保证系统不会出现故障？或者说，尽量让系统少出现故障。</li><li>万一系统出现故障了： <ul><li>怎么尽快发现出现故障了？</li><li>怎么处理出现的故障？</li><li>怎么从故障中恢复过来？或者说，怎么退出故障处理机制，恢复正常的业务处理流程？</li></ul></li></ul><p>这也就是整个故障处理的理论：</p><ul><li>故障检测</li><li>故障处理</li><li>故障恢复</li></ul><h3 id="故障检测" tabindex="-1">故障检测 <a class="header-anchor" href="#故障检测" aria-label="Permalink to &quot;故障检测&quot;">​</a></h3><ul><li>静态检测（设置阈值）</li><li>动态检测（硬件信息，服务本身信息）</li></ul><h3 id="故障处理" tabindex="-1">故障处理 <a class="header-anchor" href="#故障处理" aria-label="Permalink to &quot;故障处理&quot;">​</a></h3><ul><li>同步转异步</li></ul><blockquote><p>用 消息队列 可能遇到 消息积压 和 有序消息 的问题</p></blockquote><ul><li>执行特殊代码</li></ul><blockquote><p>可能返回 err 或者 默认值</p><p>或者 执行一个快路径</p></blockquote><ul><li>请求转发</li></ul><h3 id="故障恢复" tabindex="-1">故障恢复 <a class="header-anchor" href="#故障恢复" aria-label="Permalink to &quot;故障恢复&quot;">​</a></h3><p>该如何确定我的服务是否已经恢复正常了？</p><ul><li>固定时间等待：例如说等一分钟，就认为已经恢复了</li><li>实时计算：也就是根据故障检测的算法，实时计算服务端节点的状态</li><li>试探法：尝试处理请求，而后根据处理结果，来确定系统是否已经恢复</li></ul><p>避免抖动：也就是退出故障处理流程的时候，不要立刻引起系统再次触发故障。基本思路就是：</p><ul><li>结合试探法来逐步放开流量，也可以叫做灰度</li></ul><h4 id="几乎通用的策略" tabindex="-1">几乎通用的策略 <a class="header-anchor" href="#几乎通用的策略" aria-label="Permalink to &quot;几乎通用的策略&quot;">​</a></h4><p>大部分时候，故障恢复都可以采用试探 + 逐步放开流量的方式来进行。这里以系统发生故障之后所有请求都返回默认值为例。</p><ul><li>首先，触发故障修复（返回了默认值）之后，间隔一段时间就试探性地处理一个请求</li><li>如果该请求被正常处理了，那么就加大流量；如果没有被正常处理，那么就继续返回默认值</li><li>在逐步加大流量的过程中，如果要是请求又没有被正常处理，那么就减少流量，或者再次进入到返回默认值的状态</li><li>在不断加大流量之后，直到 100% 的流量都被正常处理了</li></ul><p>这种政策， 你可以参考之前我们随机数 + 阈值的流量控制方案。你只需要在这里根据处理结果实时调整阈值就可以</p><h2 id="微服务流量放大与雪崩" tabindex="-1">微服务流量放大与雪崩 <a class="header-anchor" href="#微服务流量放大与雪崩" aria-label="Permalink to &quot;微服务流量放大与雪崩&quot;">​</a></h2><p>也就是在微服务架构里面，有一个很重要的特性，就是一个单一请求在微服务处理过程中，会产生非常多的服务调用</p><p>可以看到，一旦请求本身流量增长了一倍，那么整个系统的实际负载增长，不止一倍</p><p>所以我们在做服务治理的时候，也要考虑这个问题。例如说通过限流、熔断等措施防止服务雪崩，或者说风险扩大</p><h2 id="熔断" tabindex="-1">熔断 <a class="header-anchor" href="#熔断" aria-label="Permalink to &quot;熔断&quot;">​</a></h2><p>熔断是经常使用的一种服务治理手段。它是一种保护机制，用于防止微服务架构中的级联故障</p><p>所谓级联故障，就是因为一个节点出错之后，导致别的节点跟着出错。本质上是因为微服务架构流量放大引起的</p><h3 id="要点" tabindex="-1">要点 <a class="header-anchor" href="#要点" aria-label="Permalink to &quot;要点&quot;">​</a></h3><p>熔断的要点在于：</p><ul><li>如何判定服务是否需要熔断了？这也就是我们之前说的故障检测，也就是可以考虑静态检测和动态检测</li><li>熔断之后怎么办？大多数时候都是返回特定错误</li><li>怎么从熔断之中恢复过来？也一样是试探请求 + 逐步放开流量。</li></ul><p>熔断还有一种说法，是说熔断处于三种状态：</p><ul><li>开放状态：也就是所有的请求都返回特定错误</li><li>闭合状态：也就是所有的请求都被正常处理</li><li>半开放状态：一部分请求被正常处理，一部分请求直接返回错误</li></ul><h2 id="降级" tabindex="-1">降级 <a class="header-anchor" href="#降级" aria-label="Permalink to &quot;降级&quot;">​</a></h2><p>降级本质上和熔断差不多。如果说熔断是直接拒绝全部请求，那么降级就是尽可能返回一个响应。这个响应可以直接是一个提前配置好的默认响应，也可以是走某些特定的快路径</p><p>正常都是先执行快路径，再执行慢路径。在降级之后，可以只执行快路径，而不执行慢路径</p><h3 id="缓存降级方案" tabindex="-1">缓存降级方案 <a class="header-anchor" href="#缓存降级方案" aria-label="Permalink to &quot;缓存降级方案&quot;">​</a></h3><p>一个非常好的面试方案就是将降级用于查询过程</p><p>在正常时候，我们都是先查询 Redis。如果 Redis 查询不到，则查询数据库，再回写缓存</p><p>但是在降级的时候，我们只查询 Redis。Redis 查询到了，则直接返回数据；如果 Redis 查询不到，则直接返回错误，或者兜底的默认值</p><p>这种策略的优势在于</p><ul><li>应用本身的负载会快速降低。因为只查询 Redis，所以会很快，因此请求被快速处理完毕，就能腾出资源来</li><li>能撑住极高并发。整个瓶颈变成了 Redis。注意，即便缓存命中率极高，但是少数的数据库查询也会极大拖累并发</li><li>能保住数据库。例如说 Redis 本身有问题，或者网络有问题，在这种策略之下，数据库不会被请求压垮</li></ul><h3 id="跨服务降级" tabindex="-1">跨服务降级 <a class="header-anchor" href="#跨服务降级" aria-label="Permalink to &quot;跨服务降级&quot;">​</a></h3><p>例如说在用户服务上，有增删改和查询服务。那么在资源不足的时候，就可以考虑将增删改停掉，全力支持查询服务</p><p>类似地可以做得更加高级：</p><ul><li>在集群层面上，如果服务器资源不足，那么就将边缘业务停掉，腾出服务器资源来给核心服务</li><li>如果是读服务和写服务分组部署的模式，那么也可以将写服务停掉，调用资源支持读服务</li><li>同一个节点上部署的不同服务，可以按照重要性从不重要到重要，逐步停掉服务，直到腾出来足够的资源</li></ul><h2 id="限流" tabindex="-1">限流 <a class="header-anchor" href="#限流" aria-label="Permalink to &quot;限流&quot;">​</a></h2><p>限流是指，当判定系统已经无法处理更多的请求的时候，就会执行限流策略</p><h3 id="被限流的请求怎么办" tabindex="-1">被限流的请求怎么办？ <a class="header-anchor" href="#被限流的请求怎么办" aria-label="Permalink to &quot;被限流的请求怎么办？&quot;">​</a></h3><p>很少有人会仔细讨论限流中被限流的请求该怎么办？</p><p>实际上也可以考虑：</p><ul><li>同步转异步：也就是被限流的请求临时保存下来，后续再处理</li><li>执行特殊代码：例如直接返回默认值</li><li>转发请求：例如说通知客户端换一个节点重试</li></ul><p>从这里你就能看出来，限流、熔断和降级之间的界限不是非常分明</p><h3 id="针对什么限流" tabindex="-1">针对什么限流？ <a class="header-anchor" href="#针对什么限流" aria-label="Permalink to &quot;针对什么限流？&quot;">​</a></h3><p>在实践中，你可以考虑：</p><ul><li>针对单机限流，或者针对集群限流</li><li>针对整个应用限流，也可以针对应用提供的某个服务限流。例如说可以整个用户服务限流，也可以是用户服务内部的某个接口（例如说更新信息）限流</li><li>针对业务对象限流：这个就可以完全根据你的业务特征来设置，非常灵活 <ul><li>针对用户限流：例如说 VIP 用户不限流，但是普通用户限流</li><li>针对 IP 限流：我们之前在 Web 登录阶段采用过</li></ul></li></ul><h3 id="限流算法" tabindex="-1">限流算法 <a class="header-anchor" href="#限流算法" aria-label="Permalink to &quot;限流算法&quot;">​</a></h3><ul><li><p>计数器</p><blockquote><p>收到请求的时候，计数器 +1；返回响应的时候，计数器-1</p></blockquote></li><li><p>固定窗口</p><blockquote><p>将时间切成一个个窗口，确保每个窗口内的请求数量没有超过阈值</p></blockquote></li><li><p>滑动窗口</p><blockquote><p>你可以认为自始至终只有一个窗口，这个窗口就是从当前时间往前回溯窗口大小的一段时间，在这个窗口内，只能处理固定数量的请求</p></blockquote></li><li><p>令牌桶</p><blockquote><p>令牌桶算法要点：</p><ul><li>有一个人按一定的速率发令牌</li><li>令牌会被放到一个桶里</li><li>每一个请求从桶里面拿一个令牌</li><li>拿到令牌的请求就会被处理</li><li>没有拿到令牌的请求就会： <ul><li>直接被拒绝</li><li>阻塞直到拿到令牌或者超时</li></ul></li></ul><p>允许积压。也就是说可以攒一些令牌，那么突发流量来的时候，有更多的请求可以拿到令牌</p></blockquote></li><li><p>漏桶</p><blockquote><p>限流算法：漏桶漏桶算法要点：</p><ul><li>有一个人按一定的速率发令牌</li><li>每一个请求拿一个令牌</li><li>拿到令牌的请求就会被处理</li><li>没有拿到令牌的请求就会： <ul><li>直接被拒绝</li><li>阻塞直到拿到令牌或者超时</li></ul></li></ul><p>没有积压，绝对均匀。漏桶可以做到，不管什么时候，放过去请求的速率都是均匀的</p></blockquote></li></ul><h2 id="总结-熔断、限流、降级用哪个" tabindex="-1">总结：熔断、限流、降级用哪个？ <a class="header-anchor" href="#总结-熔断、限流、降级用哪个" aria-label="Permalink to &quot;总结：熔断、限流、降级用哪个？&quot;">​</a></h2><ul><li>如果你希望即便出现了各种故障，但是服务也要尽可能保持可用，那么应该使用降级</li><li>如果你希望服务尽快从故障中恢复过来，那么应该选用熔断</li><li>如果你希望至少有一部分请求能够被正确处理，那么应该选用限流</li></ul><h2 id="总结-动态判定" tabindex="-1">总结：动态判定 <a class="header-anchor" href="#总结-动态判定" aria-label="Permalink to &quot;总结：动态判定&quot;">​</a></h2><p>正如之前我们多次学到的，你完全可以根据实际业务、服务信息来判定服务的状态</p><p>可以是硬件指标：例如 CPU、内存、磁盘 IO</p><p>可以是服务指标：例如响应时间，超时比率等</p><p>而后，一旦判定服务已经出现故障了，就可以从熔断、限流、降级里面挑一个来执行</p><p>最后恢复过程，同样可以综合硬件指标和服务指标，来判定是加大流量还是降低流量</p><p>PS：实践中，很少采用这种复杂的策略，也就是出去宣讲、汇报、晋升答辩、面试的时候会吹嘘这种策略</p><p>限流阈值如何确定？ 压测</p>',72),r=[t];function p(u,h,n,d,c,s){return a(),i("div",null,r)}const k=l(o,[["render",p]]);export{q as __pageData,k as default};
