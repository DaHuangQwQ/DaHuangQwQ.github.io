import{_ as l,c as e,a2 as t,o as s}from"./chunks/framework.BQmytedh.js";const a="/assets/redis-cluster.mwrSgGR1.png",r="/assets/redis-key.BLVlWMNy.png",c=JSON.parse('{"title":"redis","description":"","frontmatter":{},"headers":[],"relativePath":"labnote/go/redis.md","filePath":"labnote/go/redis.md"}'),n={name:"labnote/go/redis.md"};function o(d,i,p,u,h,R){return s(),e("div",null,i[0]||(i[0]=[t('<h1 id="redis" tabindex="-1">redis <a class="header-anchor" href="#redis" aria-label="Permalink to &quot;redis&quot;">​</a></h1><h2 id="redis-应用场景" tabindex="-1">redis 应用场景 <a class="header-anchor" href="#redis-应用场景" aria-label="Permalink to &quot;redis 应用场景&quot;">​</a></h2><ul><li>String类型，首先是热点数据的缓存，再者比较多的就是通过它的incr实现计数，来统计点赞数，播放量，访问量场景，以及进行全局id的生成。而后比较高端就是实现分布式锁，以及布隆过滤器；</li><li>Hash类型，则用在比如说用户不同场景维度的发私信的频控，以及电商类的客户的购物车信息，抖音作品的播放、点赞、收藏等系列数据；</li><li>List 类型，适用于有序但不频繁随机访问的场景，用的比较少。例如说用来实现限流算法，以及关注列表等；</li><li>Set类型，使用在比如说在社交类的场景里面可以用于用户推荐、好友关系（例如我关注了谁，谁关注了我，哪些是互关好友）、存储共同关注的人，推荐可能认识的人等；</li><li>ZSet类型，使用场景如最近听歌数据，最近联系的人，送礼排行榜，热搜榜；</li></ul><ol><li>缓存，一般来说根据缓存的数据不同，可以是缓存字符串，或者是 List 结构、哈希结构。一般来说引入 Redis 作为缓存之后，性能会有数量级的提升</li><li>滑动窗口算法，用于限流。其基本的思路就是用 List 来维持住流量进来的时间戳，而后每次判定限流的时候则是判定时间窗内有多少时间戳，也就是已经有多少流量了，而这本质上就是一个 Range 的用法。当然在实现的过程中是使用 Lua 脚本来完成的</li><li>榜单问题。这个榜单问题的核心就是利用 ZSet 来排序，对应的 score 则是根据排序规则来计算。比如说根据时间、点赞和评论数等计算一个热度，把这个热度作为 score。每次获取前几名，也就是执行一次 Range 而已。</li><li>分布式锁。使用 Redis 来设计分布式锁的关键点有两个：使用 SETNX 来排他性的设置一个值；要考虑续约的问题。也就是在设置了一定的过期时间之后，如果在快要过期了业务还没执行完毕，那么要考虑续约的问题，防止分布式锁因为过期而失效。</li></ol><h2 id="redis-数据结构" tabindex="-1">redis 数据结构 <a class="header-anchor" href="#redis-数据结构" aria-label="Permalink to &quot;redis 数据结构&quot;">​</a></h2><ul><li>字符串（String） <ul><li>底层实现：简单动态字符串（SDS）</li><li>特点：适用于存储单个值，如用户 session、缓存对象。</li><li>场景：大部分简单数据的缓存都是使用这个数据结构的</li></ul></li><li>列表（List） <ul><li>底层实现：有两种实现，ziplist，quicklist（链表）（难点）</li><li>特点：适用于存储有序元素，如消息队列、文章列表。</li><li>场景：例如说收藏夹中的收藏列表，好友列表等，有些公司还会用作消息队列。List 还有一个使用场景，就是可以用来实现滑动窗口算法，达成限流的效果。</li></ul></li><li>集合（Set） <ul><li>底层实现：hashtable 和 intset</li><li>特点：适用于存储无序且唯一元素，如标签、用户关注列表。</li><li>场景：很多都是利用集合求差集、并集或者交集。比如说共同好友、共同关注的人这种社交的应用。</li></ul></li><li>有序集合（Sorted Set） <ul><li>底层实现：skiplist（跳表） 和 ziplist</li><li>特点：适用于存储有序且唯一元素，如排行榜、时间线。</li><li>场景：最典型的就是各种榜单了，比如说游戏里面的分数排行，或者社交平台的各种榜单，电商平台的各种榜单。</li></ul></li><li>哈希（Hash） <ul><li>底层实现： ziplist 或 hashtable （取决于元素数量和大小）</li><li>特点：适用于存储对象属性，如用户信息、配置项。</li><li>场景：适合存储有很多属性的对象，比如说在用户系统中，使用 Redis 哈希存储用户信息，键为 user:userid，字段为 name、email 等，HSET 设置属性，HGET 获取属性，读写都可以只操作部分数据，减少数据冗余。</li></ul></li><li>地理空间（Geospatial） <ul><li>底层实现：有序集合（Sorted Set）的扩展</li><li>特点：适用于存储地理空间数据，如附近的人、位置服务。</li><li>场景：计算附近的人</li></ul></li><li>位图（Bitmap） <ul><li>底层实现：字符串（String）的位操作</li><li>特点：适用于存储布尔值，如用户签到、活跃用户统计。</li><li>场景：在社交平台中，使用 Redis 位图记录用户每日签到情况，键为 signin:userid，SETBIT 设置签到，GETBIT 查询签到，节省存储空间。</li></ul></li><li>HyperLogLog <ul><li>底层实现：HyperLogLog 算法</li><li>特点：适用于统计大量数据的基数，如 UV 统计。</li><li>场景：UV 统计，在网站分析系统中，使用 Redis HyperLogLog 统计每日 UV，键为 uv:date，PFADD 添加访问记录，PFCOUNT 获取 UV 数，高效处理大数据统计。</li></ul></li><li>流（Stream） <ul><li>底层实现：Rax 树和链表</li><li>特点：适用于消息队列和日志收集，支持持久化。</li><li>场景：在监控系统 中，使用 Redis 流收集日志信息，键为 log_stream，XADD 添加日志，XREAD 读取日志，支持持久化和高吞吐量。</li></ul></li></ul><p>选择 Redis 数据结构的基本原则：</p><ul><li>功能性：也就是你选择的 Redis 数据结构至少能支持你所需要的业务场景，能够解决你的业务问题</li><li>性能：内存要少，读写操作要快</li><li>底层实现的潜在问题：要进一步评估在你的业务数据特性下，你使用的数据结构对应的底层结构究竟是什么，防止出现 intset 那种升级问题，或者 ziplist 连锁更新的问题</li><li>扩展性：典型的就是在考虑存储一个大 JSON 串还是使用 Hash 结构，如果考虑到未来存在单字段的读写情况，那么使用扩展性的问题</li></ul><blockquote><p>功能性是基础，性能是目标，底层实现是防御，扩展是未来</p></blockquote><h3 id="字典和哈希表" tabindex="-1">字典和哈希表 <a class="header-anchor" href="#字典和哈希表" aria-label="Permalink to &quot;字典和哈希表&quot;">​</a></h3><p>Redis 的 hashtable 有两个核心特征：使用拉链法解决冲突，支持渐进式 rehash。</p><p>使用拉链法就意味着 hashtable 是一个数组加链表的混合结构，也就是每个数组的元素都是一个链表。在插入数据的时候，就在链表头部插入，这样更加高效。</p><p>在查找的时候，首先根据 key 算出哈希值，而后哈希值除以数组的长度得到下标，沿着下标所在的链表进行查找。</p><p>而渐进式的 rehash 则意味着在 hashtable 里面，有 ht[0] 和 ht[1] 两个标准的哈希表，它们也代表渐进式 rehash 中的旧表和新表。而不管是扩容还是缩容都是使用渐进式 rehash 来完成的。</p><p>渐进式 rehash 的过程包含三个主要步骤。</p><ol><li>ht[1] 上创建一个新容量的哈希表。</li><li>逐步把 ht[0] 上的数据迁移到 ht[1] 上。一方面，增删改查都会触发迁移，另外一方面 Redis 的后台任务循环也会主动迁移。</li><li>ht[0] 的数据迁移完成之后，交换 ht[0] 和 ht[1] 的指针，而后将 ht[1] 置为 NULL。</li></ol><p>（分析增删改查的过程）在渐进式的 rehash 过程中，如果是增加新的 key，那么会直接在 ht[1] 上操作。</p><p>如果是删改查已有的 key，那么就会先找 ht[0] 再找 ht[1]，找到之后就执行操作。</p><p>需要注意的是，渐进式过程中，一个 key 要么出现在 ht[0] 上，要么出现在 ht[1] 上。</p><h2 id="高可用" tabindex="-1">高可用 <a class="header-anchor" href="#高可用" aria-label="Permalink to &quot;高可用&quot;">​</a></h2><p>Redis 的高可用主要是源自两套方案：Redis Sentinel 和 Redis Cluster。</p><ol><li>Redis Sentinel 本质上是一个主从集群，内部可以进一步细分为 Sentinel 集群和数据集群。Sentinel 集群监控数据集群，而后数据的首先是数据复制。也就是主节点和从节点保持数据同步，这样即便主节点崩溃了，从节点上也还有数据。其次是主从选举，也就是说主节点崩溃之后会立刻选举出来一个新的主节点，继续提供服务。不过 Redis Sentinel 的主从选举和一般主从选举有点区别，它不是从节点互相推举选出来的，而是 Sentinel 选出来的。</li><li>Redis Cluster 是一个对等结构和主从结构的混合架构。Redis Cluster 由多个节点组成，这些节点之间地位是平等的，也就是说它们构成了一个对等结构。但是从细节上来说，每一个节点都是一个主从集群，也就是说每一个节点都是类似于 Redis Sentinel 模式。Redis Cluster 利用 CRC16 将 key 分散到 16384 个槽上面，而后再次将这些槽分配给不同的节点。可以平均分，也可以不是平均分。</li></ol><p>通过这种混合模式，Redis 能有效应对各种问题。</p><ol><li>从对等结构上来说，就算是某个节点彻底不可用，也不会影响到别的节点，整个集群还是能够提供有损服务的。</li><li>从主从结构上来说，通过数据同步和主从选举，这样即便主节点崩溃了， 也能选举出来一个新的从节点顶上。</li></ol><p>Redis Cluster 这种对等集群和主从集群的混合模式，在别的中间件里面也能看到类似的设计，甚至于可以说现代的大规模分布式软件的高可用都是通过这种设计来保证的。</p><ol><li>Kafka 的一个 Topic 有多个分区，这些分区之间地位是平等的，所以可以看做是对等结构。而每一个分区本身也是一个主从结构，也有数据复制和主从选举。所以Kafka 就算一个分区出问题，或者逻辑分区的主分区出现问题，依旧能够正常对外提供服务。</li><li>MySQL 的分库分表也可以看做是这种形态。一个逻辑表被分库分表之后，每一个物理表地位都是平等的，也就是可以看做是对等结构。而每一个物理表都是存储在 MySQL 主从集群上的，那么也就是说物理表本身也有主表和从表。通过这种混合模式可以保证极高的可用性。</li></ol><h3 id="redis-cluster" tabindex="-1">Redis Cluster <a class="header-anchor" href="#redis-cluster" aria-label="Permalink to &quot;Redis Cluster&quot;">​</a></h3><p>Redis Cluster 是一个对等结构和主从结构的混合架构。Redis Cluster 由多个节点组成，这些节点之间地位是平等的，也就是说它们构成了一个对等结构。</p><p>但是从细节上来说，每一个节点都是一个主从集群，也就是说每一个节点都是类似于 Redis Sentinel 模式。</p><p><img src="'+a+'" alt="redis-cluster" loading="lazy"></p><p>Redis Cluster 利用 CRC16 将 key 分散到 16384 个槽上面，而后再次将这些槽分配给不同的节点。可以平均分，也可以不是平均分。</p><p><img src="'+r+'" alt="redis-key" loading="lazy"></p><p>通过这种混合模式，Redis 能有效应对各种问题。</p><p>首先是从对等结构上来说，就算是某个节点彻底不可用，也不会影响到别的节点，整个集群还是能够提供有损服务的。</p><p>而从主从结构上来说，通过数据同步和主从选举，这样即便主节点崩溃了， 也能选举出来一个新的从节点顶上。</p><p>Redis Cluster 能够撑住极高的并发，并且能够提供极高的可用性，所以已经成了当下大规模分布式系统里面的核心组件。</p><h3 id="槽分配" tabindex="-1">槽分配 <a class="header-anchor" href="#槽分配" aria-label="Permalink to &quot;槽分配&quot;">​</a></h3><p>Redis 集群支持自动分配槽，也支持手动分配，同时还支持再平衡。所谓的再平衡就是让 Redis 重新分配这些槽</p><p>Redis Cluster 的槽分配很简单，两句话就能说清楚：CRC16算哈希值，槽分配到节点。</p><p>也就是说，针对每一个 key，Redis Cluster 会用 CRC16 计算一个哈希值。而后这个哈希值会被映射过去 16384 （2 ^ 14）个槽上，Redis Cluster 再把这些槽分配到节点上。</p><p>Redis Cluster 使用 16384 个槽是<strong>为了在性能、资源消耗和可扩展性之间取得平衡</strong>。</p><p>当客户端读写 key 的时候，客户端可以在初始化的时候，使用 CLUSTER NODES 命令拿到槽分配的情况，而后自己利用 CRC16 计算哈希值，除以 16384 的余数就是槽编号，而后根据 CLUSTER NODES 返回的数据找出 key 所在的节点，将请求发送过去。</p><p>也可以不找，随便找一个节点发过去，如果这个节点发现 key 不在自己这里，就会返回一个 MOVED 响应，告诉客户端 key 所在节点的 IP 和端口。客户端收到 MOVED 之后就可以直接把请求发送过去对应的节点上。不过这种情况下，一个请求相当于发送了两次，性能极差。</p><p>Redis Cluster 这种槽机制，虽然很大程度上避免了数据倾斜的问题，但是还是难免会出现数据倾斜、QPS 倾斜之类的问题。</p><p>在这种情况下，最好的方案就是让 Redis Cluster 执行再平衡，重新分配一下槽。但是再平衡以及槽迁移是一个很消耗性能的问题，所以正常都不太建议这么搞。</p><p>而且，槽迁移只能解决节点级别的数据倾斜和QPS倾斜的问题。但是如果要是特定的槽上面数据就是极多，或者 QPS 极高，那么 Redis Cluster 的再平衡就无能为力。更进一步来说，如果是特定某个 key 的 QPS 极高——这也是常说的热点 key，那么 Redis Cluster 也是无能为力了。</p><blockquote><p>槽数据倾斜；热点key；</p><p>CRC16算哈希，槽分配到节点，MOVED响应来指路</p><p>再平衡解决数据倾斜</p></blockquote><h2 id="主从复制" tabindex="-1">主从复制 <a class="header-anchor" href="#主从复制" aria-label="Permalink to &quot;主从复制&quot;">​</a></h2><p>Redis 的主从复制就两个：</p><ol><li><strong>全量复制</strong>：在全量复制中，从节点从主节点那里复制整个数据集。这种策略适用于从节点初次加入或者数据丢失的情况。主节点会生成一个 RDB 快照，并将其发送给从节点，从节点加载这个快照来进行复制。全量复制的缺点是，如果数据集非常大，将会占用大量的网络带宽和时间。</li><li><strong>增量复制</strong>：部分重同步是一种增量复制方式，在从节点和主节点断线后重新连接时使用。主节点会将从断线期间执行的写命令发送给从节点，使得从节点能够只接收丢失的部分数据，以此保持数据的一致性。这种方式相对于全量复制来说，节省了大量的带宽和时间。</li></ol><p>综合来看，全量复制适用于初始化同步或数据丢失的情况，而部分重同步适用于从节点和主节点断线后的重新连接。</p><p>如果站在一个节点的角度，那么当一个节点加入了主从集群之后：</p><ol><li><strong>初始化同步</strong>：从服务器连接到主服务器并发送SYNC命令请求进行初始化同步。</li><li><strong>快照传输</strong>：如果主服务器没有持久化数据到磁盘，它将执行BGSAVE命令创建一个RDB快照文件。然后，主服务器将这个快照文件发送给从服务器。</li><li><strong>增量复制</strong>：一旦快照传输完成，主服务器将继续将写命令传输给从服务器，从服务器会逐步复制主服务器上的新写命令，从而保持数据的一致性。</li><li><strong>复制偏移量</strong>：主服务器会记录传输给从服务器的最后一条写命令的偏移量，当从服务器重新连接时，会根据这个偏移量来进行增量复制，从而不重复传输已经同步过的数据。</li></ol><p>也不仅仅是 Redis 使用两种形态的复制，在所有的主从结构中，基本上都会支持两种复制模式。</p><p>举个例子，MySQL 也支持全量复制和增量复制两种形式，其中增量复制主要是依赖于 binlog 实现的，并且业界还针对这种增量复制模式搞出来很多工具，例如说 Canal，可以进一步用于监听 MySQL 的数据变更。</p><p>但是在具体实现上，不同的中间件都会有一些差异。例如说在 MySQL 的例子里面，增量复制借助 binlog 来实现，而从节点在收到 binlog 并不是直接执行这个 binlog，而是要先写入到中继日志中。但是 Redis 的从节点是立刻执行的。</p><h2 id="主从选举" tabindex="-1">主从选举 <a class="header-anchor" href="#主从选举" aria-label="Permalink to &quot;主从选举&quot;">​</a></h2><p>Redis Sentinel 集群的关键点：有一个 Redis 数据集群和一个 Redis Sentinel 集群的混合集群</p><p>你可以直接把 Redis Sentinel 看做是主从结构，而 Sentinel 就是为了解决主从选举而引入的。</p><ul><li><p>首先 Sentinel 获取了主从结构的信息，而后向所有的节点发送心跳检测。</p><ul><li>如果这个时候发现某个节点没有回复，就把它标记为主观下线；如果这个节点是主节点，那么 Sentinel 就询问别的 Sentinel 节点主节点信息。</li><li>如果大多数都 Sentinel 都认为主节点已经下线了，就认为主节点已经客观下线。</li></ul></li><li><p>当主节点已经客观下线，就要步入故障转移阶段。故障转移分成两个步骤，一个是 Sentinel 要选举一个 leader，另外一个步骤是 Sentinel leader 挑一个主节点。</p><ul><li>Sentinel leader 选举是使用 raft 算法的，选举出 leader 之后，leader 从健康从节点之中依据 &lt;优先级， 偏移量， 服务器ID&gt; 进行排序，挑出一个节点作为主节点。</li><li>找出主节点之后，Sentinel 要命令其它从节点连接新的主节点，同时保持对老的主节点的关注，在它恢复过来之后把它标记为从节点，命令它去同步新的主节点。</li></ul></li></ul><p>Redis Sentinel 和一般的主从选举有两个显著的差异。</p><ul><li>第一个是 Redis Sentinel 的主从选举并不是从节点自己推选的，而是 Sentinel 选出来的。这主要是为了： <ul><li>快速选举。Sentinel 直接挑选一个从节点要比从节点自己推举快很多，从而快速从故障中恢复；</li><li>实现简单。</li><li>独立管理。Sentinel 和数据集群是分开的，这意味着可以独立管理 Sentinel，而且不会影响数据集群；</li></ul></li><li>第二个是 Redis Sentinel 选主节点挑的是优先级（<strong>按照优先级</strong>、偏移量和服务 ID）最高的从节点，而不是有最新数据的从节点。**好处是可以借助优先级来做一些骚操作，坏处是从节点上可能没有最新数据。**最典型的场景就是在异步多活场景下，可以给本地同机房的节点更高的优先级，从而总是优先筛选本地节点。</li></ul><blockquote><p>主观标下线，客观问他人，选Leader，挑主亲，命令从连新，旧主变从跟。</p></blockquote>',63)]))}const g=l(n,[["render",o]]);export{c as __pageData,g as default};
